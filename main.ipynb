{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch documentation of resnets\n",
    "https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        # self.conv1 is simply a `point-wise convolution` changing the channels with k_s = 1 .. so no shapes changes\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # self.conv2 is changing the size of H,W but adding padding solves the mismatch shapes so we end with the same shape\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # self.conv3 we're changing the out channels by previously out channels to out cahnnels * 4\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        \"\"\"in case we have concatenating X and f(x) the we \n",
    "        change the shape of X through passing it conv and batch norm\"\"\"\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        \"\"\"self.shortcut gets applied in case of stride != 1 \n",
    "        or in_channels != out_channels * 4\n",
    "        which means the shapes has changes\"\"\"\n",
    "        out += self.shortcut(residual)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000,image_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        #shape for (1,3,214,214) -> (1,64,107,107) becuse of the stride = 2 and padding keeps the size\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        \"\"\" First residual layer -> in self.layer1 the out channels = 64 is not really\n",
    "        ending at that number of channels in fact  it will\n",
    "        be out_channels * 4 -> so it will be 256 \"\"\"\n",
    "        self.layer1 = self.make_layer(block, 64, layers[0], stride=1)\n",
    "\n",
    "        \"\"\" Second residual layer -> in self.layer2 the out channels = 128 \n",
    "        is not really ending at that number of channels\n",
    "        in fact  it will be out_channels * 4 -> so it will be 512\n",
    "        Also very important note is that stride = 2 which means that\n",
    "        shapes will change here H, W downsized by half\n",
    "        \"\"\"\n",
    "        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n",
    "\n",
    "        \"\"\" Third residual layer -> in self.layer3 the out channels = 256 \n",
    "        is not really ending at that number of channels\n",
    "        in fact  it will be out_channels * 4 -> so it will be 1024 \"\"\"\n",
    "        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)\n",
    "        \n",
    "        \"\"\" Fourth residual layer -> in self.layer4 the out channels = 512\n",
    "        is not really ending at that number of channels\n",
    "        in fact  it will be out_channels * 4 -> so it will be 2048 \"\"\"\n",
    "        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride):\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "        print(f\"before self.layer 1 {out.shape}\")\n",
    "        out = self.layer1(out)\n",
    "        print(f\"after self.layer 1 {out.shape}\")\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        print(f\"after self.layer 4 it should be 2048 : {out.shape}\")\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(Bottleneck, [2, 2, 2, 2],num_classes=10,image_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before self.layer 1 torch.Size([2, 64, 56, 56])\n",
      "after self.layer 1 torch.Size([2, 256, 56, 56])\n",
      "after self.layer 4 it should be 2048 : torch.Size([2, 2048, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "y = model(torch.randn(2, 3, 224,224))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before self.layer 1 torch.Size([2, 64, 56, 56])\n",
      "after self.layer 1 torch.Size([2, 256, 56, 56])\n",
      "after self.layer 4 it should be 2048 : torch.Size([2, 2048, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50 = ResNet50()\n",
    "y = model_50(torch.randn(2, 3, 224,224))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before self.layer 1 torch.Size([2, 64, 56, 56])\n",
      "after self.layer 1 torch.Size([2, 256, 56, 56])\n",
      "after self.layer 4 it should be 2048 : torch.Size([2, 2048, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_101 = ResNet101()\n",
    "y = model_101(torch.randn(2, 3, 224,224))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before self.layer 1 torch.Size([2, 64, 56, 56])\n",
      "after self.layer 1 torch.Size([2, 256, 56, 56])\n",
      "after self.layer 4 it should be 2048 : torch.Size([2, 2048, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[3,8,36,3]\n",
    "model_152 = ResNet152()\n",
    "y = model_152(torch.randn(2, 3, 224,224))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
